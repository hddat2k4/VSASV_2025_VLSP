{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12432698,"sourceType":"datasetVersion","datasetId":7842279},{"sourceId":12607964,"sourceType":"datasetVersion","datasetId":7964013}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Standard library\nimport os\nimport math\nimport random\nimport time\nimport zipfile\nimport shutil\nfrom pathlib import Path\nimport pathlib\nimport requests\nimport zipfile\nfrom typing import Tuple, Dict, List\n\n# Third-party libraries\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.nn.utils.rnn import pad_sequence\nfrom torch.optim import AdamW\nfrom torch.utils.data import Dataset, DataLoader, Subset, IterableDataset, SubsetRandomSampler\nimport torchaudio\nimport torchaudio.functional as Fa\nfrom torchaudio.utils import download_asset\nimport soundfile as sf\nimport librosa\nimport matplotlib.pyplot as plt\nfrom IPython.display import Audio\nfrom tqdm import tqdm\nimport wandb\nfrom safetensors.torch import load_file\nfrom transformers import Trainer, TrainingArguments\nfrom collections import defaultdict\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T15:38:25.549802Z","iopub.execute_input":"2025-08-18T15:38:25.550090Z","iopub.status.idle":"2025-08-18T15:39:11.847458Z","shell.execute_reply.started":"2025-08-18T15:38:25.550067Z","shell.execute_reply":"2025-08-18T15:39:11.846416Z"}},"outputs":[{"name":"stderr","text":"2025-08-18 15:38:49.691584: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1755531529.968836      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1755531530.061569      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Data Augmentation + Build CustomDataset","metadata":{}},{"cell_type":"markdown","source":"## Data Augmentation","metadata":{}},{"cell_type":"code","source":"SAMPLE_RATE = 16000","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T15:39:11.848531Z","iopub.execute_input":"2025-08-18T15:39:11.849795Z","iopub.status.idle":"2025-08-18T15:39:11.855372Z","shell.execute_reply.started":"2025-08-18T15:39:11.849763Z","shell.execute_reply":"2025-08-18T15:39:11.854403Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"### Add RIR","metadata":{}},{"cell_type":"code","source":"### 1. M√¥ ph·ªèng √¢m thanh vang ƒë∆∞·ª£c n√≥i trong ph√≤ng; s·ª≠ d·ª•ng t√≠ch ch·∫≠p v·ªõi RIR\n\"\"\" C√°ch l√†m:\nload waveform v√† ch·ªâ ƒë·ªãnh sample rate= 16000Hz b·∫±ng th∆∞ vi·ªán librosa\n\"\"\"\n\n# Load file audio RIR b·∫±ng librosa, cast sample rate = 16000Hz\nSAMPLE_RIR = download_asset(\"tutorial-assets/Lab41-SRI-VOiCES-rm1-impulse-mc01-stu-clo-8000hz.wav\")\nrir_waveform_librosa, rir_sample_rate_librosa = librosa.load(SAMPLE_RIR,sr = 16000)\n# convert sang tensor\nrir_waveform = torch.tensor(rir_waveform_librosa)\n# First, we need to clean up the RIR. We extract the main impulse and normalize it by its power.\nrir_waveform = rir_waveform[int(SAMPLE_RATE * 1.01) : int(SAMPLE_RATE * 1.3)]\nrir_waveform = rir_waveform / torch.norm(rir_waveform, p=2)\n\n# Then, by using: torchaudio.functional.fftconvolve(), we convolve the speech signal with the RIR.\ndef add_RIR(origin_waveform, num_frames):\n  rir_applied_waveform = Fa.fftconvolve(origin_waveform, rir_waveform)\n  return rir_applied_waveform[: num_frames * 160 + 240].type(torch.float)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T15:39:11.857694Z","iopub.execute_input":"2025-08-18T15:39:11.858029Z","iopub.status.idle":"2025-08-18T15:39:27.864165Z","shell.execute_reply.started":"2025-08-18T15:39:11.857955Z","shell.execute_reply":"2025-08-18T15:39:27.862548Z"}},"outputs":[{"name":"stderr","text":"100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 31.3k/31.3k [00:00<00:00, 36.2MB/s]\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"### Add Background Noise","metadata":{}},{"cell_type":"code","source":"### 2. Background noise\nSAMPLE_NOISE = download_asset(\"tutorial-assets/Lab41-SRI-VOiCES-rm1-babb-mc01-stu-clo-8000hz.wav\")\n\ndef add_background_noise(origin_waveform):\n  noise_np, _ =  sf.read(SAMPLE_NOISE)\n  target_len = origin_waveform.shape[0]\n  noise_np = noise_np[:target_len]\n  noise_np = np.pad(noise_np, (0,target_len - len(noise_np)), 'wrap')\n  noise_np = torch.from_numpy(noise_np)\n\n  snr_db = torch.tensor(10)\n  bg_added_waveform = Fa.add_noise(origin_waveform, noise_np, snr_db)\n  return bg_added_waveform.type(torch.float)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T15:39:27.865504Z","iopub.execute_input":"2025-08-18T15:39:27.867281Z","iopub.status.idle":"2025-08-18T15:39:27.950473Z","shell.execute_reply.started":"2025-08-18T15:39:27.867241Z","shell.execute_reply":"2025-08-18T15:39:27.949604Z"}},"outputs":[{"name":"stderr","text":"100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 78.2k/78.2k [00:00<00:00, 11.6MB/s]\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"### Simulate a Phone Call","metadata":{}},{"cell_type":"code","source":"import torchaudio.transforms as T\n\ndef simulate_phone_call(origin_waveform: torch.Tensor, num_frames: int) -> torch.Tensor:\n    \"\"\"\n    M√¥ ph·ªèng audio g·ªçi ƒëi·ªán tho·∫°i (kh√¥ng d√πng torchaudio.sox_effects).\n    \"\"\"\n    # 1. Apply RIR\n    rir_applied_waveform = add_RIR(origin_waveform, num_frames)\n\n    # 2. Add background noise\n    noisy_waveform = add_background_noise(rir_applied_waveform)\n\n    # 3. Downsample v·ªÅ 8000Hz\n    downsample = T.Resample(orig_freq=16000, new_freq=8000)\n    lowrate = downsample(noisy_waveform.unsqueeze(0))  # shape (1, L)\n\n    # 4. M√¥ ph·ªèng codec: apply GSM codec (n·∫øu l·ªói th√¨ b·ªè qua)\n    try:\n        coded = Fa.apply_codec(lowrate, 8000, format=\"gsm\")  # (1, L)\n    except:\n        # N·∫øu kh√¥ng c√≥ codec th√¨ d√πng lu√¥n t√≠n hi·ªáu downsample\n        coded = lowrate\n\n    # 5. Upsample l·∫°i v·ªÅ 16kHz\n    upsample = T.Resample(orig_freq=8000, new_freq=16000)\n    final = upsample(coded)\n\n    return final.squeeze()[:num_frames * 160 + 240]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T15:39:27.951355Z","iopub.execute_input":"2025-08-18T15:39:27.951605Z","iopub.status.idle":"2025-08-18T15:39:27.960408Z","shell.execute_reply.started":"2025-08-18T15:39:27.951577Z","shell.execute_reply":"2025-08-18T15:39:27.959055Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## Add Music Noise","metadata":{}},{"cell_type":"code","source":"MUSIC_PATH = \"/kaggle/input/music-aug/music-fma-0000.wav\"\n\ndef add_music_noise(origin_waveform: torch.Tensor, snr_range=(5, 15)) -> torch.Tensor:\n    \"\"\"\n    Tr·ªôn nh·∫°c v√†o origin_waveform v·ªõi SNR 5‚Äì15 dB.\n    \"\"\"\n    # Load music file\n    music_waveform, music_sr = torchaudio.load(MUSIC_PATH)\n\n    # Resample v·ªÅ 16kHz n·∫øu c·∫ßn\n    if music_sr != 16000:\n        resample = torchaudio.transforms.Resample(orig_freq=music_sr, new_freq=16000)\n        music_waveform = resample(music_waveform)\n\n    music_waveform = music_waveform[0]  # mono\n\n    target_len = origin_waveform.shape[0]\n\n    # C·∫Øt ho·∫∑c wrap nh·∫°c\n    if music_waveform.shape[0] >= target_len:\n        music_waveform = music_waveform[:target_len]\n    else:\n        shortage = target_len - music_waveform.shape[0]\n        music_waveform = torch.cat([music_waveform, music_waveform[:shortage]], dim=0)\n\n    # === T√≠nh SNR ===\n    snr_db = random.uniform(*snr_range)\n    snr = 10 ** (snr_db / 10)\n\n    # T√≠nh nƒÉng l∆∞·ª£ng\n    power_signal = origin_waveform.pow(2).mean()\n    power_noise = music_waveform.pow(2).mean()\n\n    # T√≠nh h·ªá s·ªë scale cho noise\n    scale = torch.sqrt(power_signal / (power_noise * snr + 1e-8))\n    music_scaled = music_waveform * scale\n\n    # Tr·ªôn\n    mixed = origin_waveform + music_scaled\n    return mixed.type(torch.float)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T15:39:27.962202Z","iopub.execute_input":"2025-08-18T15:39:27.962834Z","iopub.status.idle":"2025-08-18T15:39:27.985746Z","shell.execute_reply.started":"2025-08-18T15:39:27.962807Z","shell.execute_reply":"2025-08-18T15:39:27.984458Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"### SETUP","metadata":{}},{"cell_type":"code","source":"# === SETUP ===\nINPUT_ROOT = \"/kaggle/input/vsasv-train/vlsp_train/home4/vuhl/VSASV-Dataset/vlsp2025/train\"\nOUTPUT_ROOT = \"/kaggle/working/augmented_output\"\nos.makedirs(OUTPUT_ROOT, exist_ok=True)\n\nSTART_INDEX = 50000\nEND_INDEX = 75000\n# START_INDEX = 25_001\n# END_INDEX = 50_000\n# START_INDEX = 50_001\n# END_INDEX = 75_000\n# START_INDEX = 75_001\n# END_INDEX = 100_000\nNUM_FRAMES = 400\nOUTPUT_ORIG = True  # l∆∞u c·∫£ file g·ªëc n·∫øu mu·ªën\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T15:39:27.987097Z","iopub.execute_input":"2025-08-18T15:39:27.987419Z","iopub.status.idle":"2025-08-18T15:39:28.015246Z","shell.execute_reply.started":"2025-08-18T15:39:27.987396Z","shell.execute_reply":"2025-08-18T15:39:28.014277Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"### Export to Folder","metadata":{}},{"cell_type":"code","source":"# === UTIL: L·∫•y danh s√°ch t·∫•t c·∫£ file .wav ===\ndef list_all_wavs_in_vsasv_structure(root):\n    paths = list(pathlib.Path(root).glob(\"id*/**/*.wav\"))\n    return sorted(paths)\n\n# === T·∫°o th∆∞ m·ª•c g·ªëc n·∫øu ch∆∞a c√≥ ===\nos.makedirs(OUTPUT_ROOT, exist_ok=True)\n\n# === RUN AUGMENT ===\nall_files = list_all_wavs_in_vsasv_structure(INPUT_ROOT)\n#selected_files = all_files[50000:75000]\nselected_files = all_files\nprint(f\"üîé T·ªïng s·ªë file WAV s·∫Ω x·ª≠ l√Ω: {len(selected_files)}\")\n\nfor path in tqdm(selected_files):\n    waveform_np, sr = sf.read(path)\n    length = NUM_FRAMES * 160 + 240\n\n    # Pad n·∫øu audio qu√° ng·∫Øn\n    if waveform_np.shape[0] < length:\n        shortage = length - waveform_np.shape[0]\n        waveform_np = np.pad(waveform_np, (0, shortage), mode='wrap')\n\n    start = int(random.random() * (waveform_np.shape[0] - length))\n    segment = waveform_np[start:start + length]\n    segment_tensor = torch.FloatTensor(segment)\n\n    # === AUGMENT ===\n    # r = np.random.rand()\n    # if r < 0.7:\n    #     augmented = segment_tensor\n    # elif r < 0.8:\n    augmented_RIR = add_RIR(segment_tensor, NUM_FRAMES)\n    augmented_BGNoise = add_background_noise(segment_tensor)\n    augmented_SimPhoneCall = simulate_phone_call(segment_tensor, NUM_FRAMES)\n    augmented_MusicNoise = add_music_noise(segment_tensor)\n\n    # === SAVE ===\n    # path: .../id00003/bonafide/abc.wav\n    id_folder = path.parent.parent.name  # id00003\n    label = path.parent.name             # bonafide or spoof\n    filename = path.stem\n\n    out_dir = os.path.join(OUTPUT_ROOT, id_folder, label)\n    os.makedirs(out_dir, exist_ok=True)\n\n    if OUTPUT_ORIG:\n        out_orig = os.path.join(out_dir, f\"{filename}_orig.wav\")\n        sf.write(out_orig, segment_tensor.numpy(), SAMPLE_RATE)\n\n    out_augRIR = os.path.join(out_dir, f\"{filename}_RIR.wav\")\n    sf.write(out_augRIR, augmented_RIR.numpy(), SAMPLE_RATE)\n    out_augBGNoise = os.path.join(out_dir, f\"{filename}_BGNosie.wav\")\n    sf.write(out_augBGNoise, augmented_BGNoise.numpy(), SAMPLE_RATE)\n    out_augSimPhoneCall = os.path.join(out_dir, f\"{filename}_SimPhoneCall.wav\")\n    sf.write(out_augSimPhoneCall, augmented_SimPhoneCall.numpy(), SAMPLE_RATE)\n    out_augMusicNoise = os.path.join(out_dir, f\"{filename}_MusicNoise.wav\")\n    sf.write(out_augMusicNoise, augmented_MusicNoise.numpy(), SAMPLE_RATE)\nprint(\"‚úÖ DONE\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T15:39:28.016426Z","iopub.execute_input":"2025-08-18T15:39:28.016777Z","iopub.status.idle":"2025-08-18T15:40:53.647021Z","shell.execute_reply.started":"2025-08-18T15:39:28.016747Z","shell.execute_reply":"2025-08-18T15:40:53.644889Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/512349460.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# === RUN AUGMENT ===\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mall_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist_all_wavs_in_vsasv_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mINPUT_ROOT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;31m#selected_files = all_files[50000:75000]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mselected_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/512349460.py\u001b[0m in \u001b[0;36mlist_all_wavs_in_vsasv_structure\u001b[0;34m(root)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# === UTIL: L·∫•y danh s√°ch t·∫•t c·∫£ file .wav ===\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlist_all_wavs_in_vsasv_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mpaths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"id*/**/*.wav\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/pathlib.py\u001b[0m in \u001b[0;36mglob\u001b[0;34m(self, pattern)\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mpattern_parts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0mselector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_selector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern_parts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flavour\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 953\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    954\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/pathlib.py\u001b[0m in \u001b[0;36m_select_from\u001b[0;34m(self, parent_path, is_dir, exists, scandir)\u001b[0m\n\u001b[1;32m    370\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m                     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparent_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_child_relpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuccessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_select_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscandir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mPermissionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/pathlib.py\u001b[0m in \u001b[0;36m_select_from\u001b[0;34m(self, parent_path, is_dir, exists, scandir)\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m                 \u001b[0msuccessor_select\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuccessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_select_from\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mstarting_point\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterate_directories\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscandir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuccessor_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstarting_point\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscandir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0myielded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/pathlib.py\u001b[0m in \u001b[0;36m_iterate_directories\u001b[0;34m(self, parent_path, is_dir, scandir)\u001b[0m\n\u001b[1;32m    395\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mentry_is_dir\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m                     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparent_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_child_relpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterate_directories\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscandir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mPermissionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/pathlib.py\u001b[0m in \u001b[0;36m_iterate_directories\u001b[0;34m(self, parent_path, is_dir, scandir)\u001b[0m\n\u001b[1;32m    389\u001b[0m                 \u001b[0mentry_is_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m                     \u001b[0mentry_is_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_ignore_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":8},{"cell_type":"markdown","source":"### ZIP","metadata":{}},{"cell_type":"code","source":"import os\nimport zipfile\n\nOUTPUT_DIR = \"/kaggle/working/augmented_output\"\nZIP_NAME = f\"/kaggle/working/augmented_full.zip\"\n\nwith zipfile.ZipFile(ZIP_NAME, 'w', zipfile.ZIP_DEFLATED) as zipf:\n    for root, _, files in os.walk(OUTPUT_DIR):\n        for file in files:\n            file_path = os.path.join(root, file)\n            arcname = os.path.relpath(file_path, OUTPUT_DIR)\n\n            # Th√™m file v√†o zip\n            zipf.write(file_path, arcname)\n\n            # Xo√° file sau khi ƒë√£ n√©n xong\n            os.remove(file_path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-18T15:40:53.648247Z","iopub.status.idle":"2025-08-18T15:40:53.648843Z","shell.execute_reply.started":"2025-08-18T15:40:53.648449Z","shell.execute_reply":"2025-08-18T15:40:53.648471Z"}},"outputs":[],"execution_count":null}]}