{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12432698,"sourceType":"datasetVersion","datasetId":7842279},{"sourceId":12479636,"sourceType":"datasetVersion","datasetId":7874214},{"sourceId":12713111,"sourceType":"datasetVersion","datasetId":8009999},{"sourceId":12731569,"sourceType":"datasetVersion","datasetId":8047360},{"sourceId":12723098,"sourceType":"datasetVersion","datasetId":8041670}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch import nn, Tensor\nimport math, torch, torchaudio\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom pathlib import Path\nfrom typing import Union\nimport numpy as np","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"markdown","source":"## ResNet48 Architecture","metadata":{}},{"cell_type":"code","source":"class BasicBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, stride=1):\n        super().__init__()\n        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.relu = nn.ReLU(inplace=True)\n\n        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n\n        self.downsample = None\n        if stride != 1 or in_channels != out_channels:\n            self.downsample = nn.Sequential(\n                nn.Conv2d(in_channels, out_channels, 1, stride=stride, bias=False),\n                nn.BatchNorm2d(out_channels),\n            )\n\n    def forward(self, x):\n        identity = x\n        out = self.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        if self.downsample:\n            identity = self.downsample(x)\n        out += identity\n        return self.relu(out)\n\nclass StatsPooling(nn.Module):\n    def forward(self, x):\n        # x: [B, C, F, T]  (sau stage4: [B, 256, 10, T/8])\n        B, C, F, T = x.size()\n        x = x.view(B, C * F, T)         # [B, 2560, T/8]\n        mean = x.mean(dim=2)            # [B, 2560]\n        std = x.std(dim=2)              # [B, 2560]\n        return torch.cat([mean, std], dim=1)  # [B, 5120]\n\nclass ResNet48_ASV(nn.Module):\n    def __init__(self, embedding_dim=256, num_speakers=None):\n        super().__init__()\n        # Conv0\n        self.conv1 = nn.Conv2d(1, 96, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(96)\n        self.relu = nn.ReLU(inplace=True)\n\n        # Residual stages\n        self.layer1 = self._make_layer(96, 96, 6, stride=1)    # ResBlock-1\n        self.layer2 = self._make_layer(96, 128, 8, stride=2)   # ResBlock-2\n        self.layer3 = self._make_layer(128, 160, 6, stride=2)  # ResBlock-3\n        self.layer4 = self._make_layer(160, 256, 3, stride=2)  # ResBlock-4\n\n        # Pooling + FC\n        self.pooling = StatsPooling()\n        self.fc = nn.Linear(5120, embedding_dim)\n\n        # Classifier (optional)\n        if num_speakers:\n            self.classifier = nn.Linear(embedding_dim, num_speakers)\n        else:\n            self.classifier = None\n\n    def _make_layer(self, in_c, out_c, num_blocks, stride):\n        layers = [BasicBlock(in_c, out_c, stride)]\n        for _ in range(1, num_blocks):\n            layers.append(BasicBlock(out_c, out_c))\n        return nn.Sequential(*layers)\n\n    def forward(self, input_values, labels=None):\n        # Backbone\n        x = self.relu(self.bn1(self.conv1(input_values)))\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        # StatsPooling\n        x = self.pooling(x)\n\n        # Dense → embedding\n        embeddings = F.normalize(self.fc(x), dim=1)  # [B, 256]\n        return embeddings","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-11T11:23:57.602018Z","iopub.execute_input":"2025-08-11T11:23:57.602310Z","iopub.status.idle":"2025-08-11T11:23:57.616031Z","shell.execute_reply.started":"2025-08-11T11:23:57.602289Z","shell.execute_reply":"2025-08-11T11:23:57.615185Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"## AASIST Architecture","metadata":{}},{"cell_type":"code","source":"class GraphAttentionLayer(nn.Module):\n    def __init__(self, in_dim, out_dim, **kwargs):\n        super().__init__()\n\n        # attention map\n        self.att_proj = nn.Linear(in_dim, out_dim)\n        self.att_weight = self._init_new_params(out_dim, 1)\n\n        # project\n        self.proj_with_att = nn.Linear(in_dim, out_dim)\n        self.proj_without_att = nn.Linear(in_dim, out_dim)\n\n        # batch norm\n        self.bn = nn.BatchNorm1d(out_dim)\n\n        # dropout for inputs\n        self.input_drop = nn.Dropout(p=0.2)\n\n        # activate\n        self.act = nn.SELU(inplace=True)\n\n        # temperature\n        self.temp = 1.\n        if \"temperature\" in kwargs:\n            self.temp = kwargs[\"temperature\"]\n\n    def forward(self, x):\n        '''\n        x   :(#bs, #node, #dim)\n        '''\n        # apply input dropout\n        x = self.input_drop(x)\n\n        # derive attention map\n        att_map = self._derive_att_map(x)\n\n        # projection\n        x = self._project(x, att_map)\n\n        # apply batch norm\n        x = self._apply_BN(x)\n        x = self.act(x)\n        return x\n\n    def _pairwise_mul_nodes(self, x):\n        '''\n        Calculates pairwise multiplication of nodes.\n        - for attention map\n        x           :(#bs, #node, #dim)\n        out_shape   :(#bs, #node, #node, #dim)\n        '''\n\n        nb_nodes = x.size(1)\n        x = x.unsqueeze(2).expand(-1, -1, nb_nodes, -1)\n        x_mirror = x.transpose(1, 2)\n\n        return x * x_mirror\n\n    def _derive_att_map(self, x):\n        '''\n        x           :(#bs, #node, #dim)\n        out_shape   :(#bs, #node, #node, 1)\n        '''\n        att_map = self._pairwise_mul_nodes(x)\n        # size: (#bs, #node, #node, #dim_out)\n        att_map = torch.tanh(self.att_proj(att_map))\n        # size: (#bs, #node, #node, 1)\n        att_map = torch.matmul(att_map, self.att_weight)\n\n        # apply temperature\n        att_map = att_map / self.temp\n\n        att_map = F.softmax(att_map, dim=-2)\n\n        return att_map\n\n    def _project(self, x, att_map):\n        x1 = self.proj_with_att(torch.matmul(att_map.squeeze(-1), x))\n        x2 = self.proj_without_att(x)\n\n        return x1 + x2\n\n    def _apply_BN(self, x):\n        org_size = x.size()\n        x = x.view(-1, org_size[-1])\n        x = self.bn(x)\n        x = x.view(org_size)\n\n        return x\n\n    def _init_new_params(self, *size):\n        out = nn.Parameter(torch.FloatTensor(*size))\n        nn.init.xavier_normal_(out)\n        return out\n\n\nclass HtrgGraphAttentionLayer(nn.Module):\n    def __init__(self, in_dim, out_dim, **kwargs):\n        super().__init__()\n\n        self.proj_type1 = nn.Linear(in_dim, in_dim)\n        self.proj_type2 = nn.Linear(in_dim, in_dim)\n\n        # attention map\n        self.att_proj = nn.Linear(in_dim, out_dim)\n        self.att_projM = nn.Linear(in_dim, out_dim)\n\n        self.att_weight11 = self._init_new_params(out_dim, 1)\n        self.att_weight22 = self._init_new_params(out_dim, 1)\n        self.att_weight12 = self._init_new_params(out_dim, 1)\n        self.att_weightM = self._init_new_params(out_dim, 1)\n\n        # project\n        self.proj_with_att = nn.Linear(in_dim, out_dim)\n        self.proj_without_att = nn.Linear(in_dim, out_dim)\n\n        self.proj_with_attM = nn.Linear(in_dim, out_dim)\n        self.proj_without_attM = nn.Linear(in_dim, out_dim)\n\n        # batch norm\n        self.bn = nn.BatchNorm1d(out_dim)\n\n        # dropout for inputs\n        self.input_drop = nn.Dropout(p=0.2)\n\n        # activate\n        self.act = nn.SELU(inplace=True)\n\n        # temperature\n        self.temp = 1.\n        if \"temperature\" in kwargs:\n            self.temp = kwargs[\"temperature\"]\n\n    def forward(self, x1, x2, master=None):\n        '''\n        x1  :(#bs, #node, #dim)\n        x2  :(#bs, #node, #dim)\n        '''\n        num_type1 = x1.size(1)\n        num_type2 = x2.size(1)\n\n        x1 = self.proj_type1(x1)\n        x2 = self.proj_type2(x2)\n\n        x = torch.cat([x1, x2], dim=1)\n\n        if master is None:\n            master = torch.mean(x, dim=1, keepdim=True)\n\n        # apply input dropout\n        x = self.input_drop(x)\n\n        # derive attention map\n        att_map = self._derive_att_map(x, num_type1, num_type2)\n\n        # directional edge for master node\n        master = self._update_master(x, master)\n\n        # projection\n        x = self._project(x, att_map)\n\n        # apply batch norm\n        x = self._apply_BN(x)\n        x = self.act(x)\n\n        x1 = x.narrow(1, 0, num_type1)\n        x2 = x.narrow(1, num_type1, num_type2)\n\n        return x1, x2, master\n\n    def _update_master(self, x, master):\n\n        att_map = self._derive_att_map_master(x, master)\n        master = self._project_master(x, master, att_map)\n\n        return master\n\n    def _pairwise_mul_nodes(self, x):\n        '''\n        Calculates pairwise multiplication of nodes.\n        - for attention map\n        x           :(#bs, #node, #dim)\n        out_shape   :(#bs, #node, #node, #dim)\n        '''\n\n        nb_nodes = x.size(1)\n        x = x.unsqueeze(2).expand(-1, -1, nb_nodes, -1)\n        x_mirror = x.transpose(1, 2)\n\n        return x * x_mirror\n\n    def _derive_att_map_master(self, x, master):\n        '''\n        x           :(#bs, #node, #dim)\n        out_shape   :(#bs, #node, #node, 1)\n        '''\n        att_map = x * master\n        att_map = torch.tanh(self.att_projM(att_map))\n\n        att_map = torch.matmul(att_map, self.att_weightM)\n\n        # apply temperature\n        att_map = att_map / self.temp\n\n        att_map = F.softmax(att_map, dim=-2)\n\n        return att_map\n\n    def _derive_att_map(self, x, num_type1, num_type2):\n        '''\n        x           :(#bs, #node, #dim)\n        out_shape   :(#bs, #node, #node, 1)\n        '''\n        att_map = self._pairwise_mul_nodes(x)\n        # size: (#bs, #node, #node, #dim_out)\n        att_map = torch.tanh(self.att_proj(att_map))\n        # size: (#bs, #node, #node, 1)\n\n        att_board = torch.zeros_like(att_map[:, :, :, 0]).unsqueeze(-1)\n\n        att_board[:, :num_type1, :num_type1, :] = torch.matmul(\n            att_map[:, :num_type1, :num_type1, :], self.att_weight11)\n        att_board[:, num_type1:, num_type1:, :] = torch.matmul(\n            att_map[:, num_type1:, num_type1:, :], self.att_weight22)\n        att_board[:, :num_type1, num_type1:, :] = torch.matmul(\n            att_map[:, :num_type1, num_type1:, :], self.att_weight12)\n        att_board[:, num_type1:, :num_type1, :] = torch.matmul(\n            att_map[:, num_type1:, :num_type1, :], self.att_weight12)\n\n        att_map = att_board\n\n        # att_map = torch.matmul(att_map, self.att_weight12)\n\n        # apply temperature\n        att_map = att_map / self.temp\n\n        att_map = F.softmax(att_map, dim=-2)\n\n        return att_map\n\n    def _project(self, x, att_map):\n        x1 = self.proj_with_att(torch.matmul(att_map.squeeze(-1), x))\n        x2 = self.proj_without_att(x)\n\n        return x1 + x2\n\n    def _project_master(self, x, master, att_map):\n\n        x1 = self.proj_with_attM(torch.matmul(\n            att_map.squeeze(-1).unsqueeze(1), x))\n        x2 = self.proj_without_attM(master)\n\n        return x1 + x2\n\n    def _apply_BN(self, x):\n        org_size = x.size()\n        x = x.view(-1, org_size[-1])\n        x = self.bn(x)\n        x = x.view(org_size)\n\n        return x\n\n    def _init_new_params(self, *size):\n        out = nn.Parameter(torch.FloatTensor(*size))\n        nn.init.xavier_normal_(out)\n        return out\n\n\nclass GraphPool(nn.Module):\n    def __init__(self, k: float, in_dim: int, p: Union[float, int]):\n        super().__init__()\n        self.k = k\n        self.sigmoid = nn.Sigmoid()\n        self.proj = nn.Linear(in_dim, 1)\n        self.drop = nn.Dropout(p=p) if p > 0 else nn.Identity()\n        self.in_dim = in_dim\n\n    def forward(self, h):\n        Z = self.drop(h)\n        weights = self.proj(Z)\n        scores = self.sigmoid(weights)\n        new_h = self.top_k_graph(scores, h, self.k)\n\n        return new_h\n\n    def top_k_graph(self, scores, h, k):\n        \"\"\"\n        args\n        =====\n        scores: attention-based weights (#bs, #node, 1)\n        h: graph data (#bs, #node, #dim)\n        k: ratio of remaining nodes, (float)\n\n        returns\n        =====\n        h: graph pool applied data (#bs, #node', #dim)\n        \"\"\"\n        _, n_nodes, n_feat = h.size()\n        n_nodes = max(int(n_nodes * k), 1)\n        _, idx = torch.topk(scores, n_nodes, dim=1)\n        idx = idx.expand(-1, -1, n_feat)\n\n        h = h * scores\n        h = torch.gather(h, 1, idx)\n\n        return h\n\n\nclass CONV(nn.Module):\n    @staticmethod\n    def to_mel(hz):\n        return 2595 * np.log10(1 + hz / 700)\n\n    @staticmethod\n    def to_hz(mel):\n        return 700 * (10**(mel / 2595) - 1)\n\n    def __init__(self,\n                 out_channels,\n                 kernel_size,\n                 sample_rate=16000,\n                 in_channels=1,\n                 stride=1,\n                 padding=0,\n                 dilation=1,\n                 bias=False,\n                 groups=1,\n                 mask=False):\n        super().__init__()\n        if in_channels != 1:\n\n            msg = \"SincConv only support one input channel (here, in_channels = {%i})\" % (\n                in_channels)\n            raise ValueError(msg)\n        self.out_channels = out_channels\n        self.kernel_size = kernel_size\n        self.sample_rate = sample_rate\n\n        # Forcing the filters to be odd (i.e, perfectly symmetrics)\n        if kernel_size % 2 == 0:\n            self.kernel_size = self.kernel_size + 1\n        self.stride = stride\n        self.padding = padding\n        self.dilation = dilation\n        self.mask = mask\n        if bias:\n            raise ValueError('SincConv does not support bias.')\n        if groups > 1:\n            raise ValueError('SincConv does not support groups.')\n\n        NFFT = 512\n        f = int(self.sample_rate / 2) * np.linspace(0, 1, int(NFFT / 2) + 1)\n        fmel = self.to_mel(f)\n        fmelmax = np.max(fmel)\n        fmelmin = np.min(fmel)\n        filbandwidthsmel = np.linspace(fmelmin, fmelmax, self.out_channels + 1)\n        filbandwidthsf = self.to_hz(filbandwidthsmel)\n\n        self.mel = filbandwidthsf\n        self.hsupp = torch.arange(-(self.kernel_size - 1) / 2,\n                                  (self.kernel_size - 1) / 2 + 1)\n        self.band_pass = torch.zeros(self.out_channels, self.kernel_size)\n        for i in range(len(self.mel) - 1):\n            fmin = self.mel[i]\n            fmax = self.mel[i + 1]\n            hHigh = (2*fmax/self.sample_rate) * \\\n                np.sinc(2*fmax*self.hsupp/self.sample_rate)\n            hLow = (2*fmin/self.sample_rate) * \\\n                np.sinc(2*fmin*self.hsupp/self.sample_rate)\n            hideal = hHigh - hLow\n\n            self.band_pass[i, :] = Tensor(np.hamming(\n                self.kernel_size)) * Tensor(hideal)\n\n    def forward(self, x, mask=False):\n        band_pass_filter = self.band_pass.clone().to(x.device)\n        if mask:\n            A = np.random.uniform(0, 20)\n            A = int(A)\n            A0 = random.randint(0, band_pass_filter.shape[0] - A)\n            band_pass_filter[A0:A0 + A, :] = 0\n        else:\n            band_pass_filter = band_pass_filter\n\n        self.filters = (band_pass_filter).view(self.out_channels, 1,\n                                               self.kernel_size)\n\n        return F.conv1d(x,\n                        self.filters,\n                        stride=self.stride,\n                        padding=self.padding,\n                        dilation=self.dilation,\n                        bias=None,\n                        groups=1)\n\n\nclass Residual_block(nn.Module):\n    def __init__(self, nb_filts, first=False):\n        super().__init__()\n        self.first = first\n\n        if not self.first:\n            self.bn1 = nn.BatchNorm2d(num_features=nb_filts[0])\n        self.conv1 = nn.Conv2d(in_channels=nb_filts[0],\n                               out_channels=nb_filts[1],\n                               kernel_size=(2, 3),\n                               padding=(1, 1),\n                               stride=1)\n        self.selu = nn.SELU(inplace=True)\n\n        self.bn2 = nn.BatchNorm2d(num_features=nb_filts[1])\n        self.conv2 = nn.Conv2d(in_channels=nb_filts[1],\n                               out_channels=nb_filts[1],\n                               kernel_size=(2, 3),\n                               padding=(0, 1),\n                               stride=1)\n\n        if nb_filts[0] != nb_filts[1]:\n            self.downsample = True\n            self.conv_downsample = nn.Conv2d(in_channels=nb_filts[0],\n                                             out_channels=nb_filts[1],\n                                             padding=(0, 1),\n                                             kernel_size=(1, 3),\n                                             stride=1)\n\n        else:\n            self.downsample = False\n        self.mp = nn.MaxPool2d((1, 3))  # self.mp = nn.MaxPool2d((1,4))\n\n    def forward(self, x):\n        identity = x\n        if not self.first:\n            out = self.bn1(x)\n            out = self.selu(out)\n        else:\n            out = x\n        out = self.conv1(x)\n\n        # print('out',out.shape)\n        out = self.bn2(out)\n        out = self.selu(out)\n        # print('out',out.shape)\n        out = self.conv2(out)\n        #print('conv2 out',out.shape)\n        if self.downsample:\n            identity = self.conv_downsample(identity)\n\n        out += identity\n        out = self.mp(out)\n        return out\n\n\nclass AASIST_Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        d_args = {\n        \"architecture\": \"AASIST\",\n        \"nb_samp\": 64600,\n        \"first_conv\": 128,\n        \"filts\": [70, [1, 32], [32, 32], [32, 64], [64, 64]],\n        \"gat_dims\": [64, 32],\n        \"pool_ratios\": [0.5, 0.7, 0.5, 0.5],\n        \"temperatures\": [2.0, 2.0, 100.0, 100.0]\n        }\n\n        self.d_args = d_args\n        filts = d_args[\"filts\"]\n        gat_dims = d_args[\"gat_dims\"]\n        pool_ratios = d_args[\"pool_ratios\"]\n        temperatures = d_args[\"temperatures\"]\n\n        self.conv_time = CONV(out_channels=filts[0],\n                              kernel_size=d_args[\"first_conv\"],\n                              in_channels=1)\n        self.first_bn = nn.BatchNorm2d(num_features=1)\n\n        self.drop = nn.Dropout(0.5, inplace=True)\n        self.drop_way = nn.Dropout(0.2, inplace=True)\n        self.selu = nn.SELU(inplace=True)\n\n        self.encoder = nn.Sequential(\n            nn.Sequential(Residual_block(nb_filts=filts[1], first=True)),\n            nn.Sequential(Residual_block(nb_filts=filts[2])),\n            nn.Sequential(Residual_block(nb_filts=filts[3])),\n            nn.Sequential(Residual_block(nb_filts=filts[4])),\n            nn.Sequential(Residual_block(nb_filts=filts[4])),\n            nn.Sequential(Residual_block(nb_filts=filts[4])))\n\n        self.pos_S = nn.Parameter(torch.randn(1, 23, filts[-1][-1]))\n        self.master1 = nn.Parameter(torch.randn(1, 1, gat_dims[0]))\n        self.master2 = nn.Parameter(torch.randn(1, 1, gat_dims[0]))\n\n        self.GAT_layer_S = GraphAttentionLayer(filts[-1][-1],\n                                               gat_dims[0],\n                                               temperature=temperatures[0])\n        self.GAT_layer_T = GraphAttentionLayer(filts[-1][-1],\n                                               gat_dims[0],\n                                               temperature=temperatures[1])\n\n        self.HtrgGAT_layer_ST11 = HtrgGraphAttentionLayer(\n            gat_dims[0], gat_dims[1], temperature=temperatures[2])\n        self.HtrgGAT_layer_ST12 = HtrgGraphAttentionLayer(\n            gat_dims[1], gat_dims[1], temperature=temperatures[2])\n\n        self.HtrgGAT_layer_ST21 = HtrgGraphAttentionLayer(\n            gat_dims[0], gat_dims[1], temperature=temperatures[2])\n\n        self.HtrgGAT_layer_ST22 = HtrgGraphAttentionLayer(\n            gat_dims[1], gat_dims[1], temperature=temperatures[2])\n\n        self.pool_S = GraphPool(pool_ratios[0], gat_dims[0], 0.3)\n        self.pool_T = GraphPool(pool_ratios[1], gat_dims[0], 0.3)\n        self.pool_hS1 = GraphPool(pool_ratios[2], gat_dims[1], 0.3)\n        self.pool_hT1 = GraphPool(pool_ratios[2], gat_dims[1], 0.3)\n\n        self.pool_hS2 = GraphPool(pool_ratios[2], gat_dims[1], 0.3)\n        self.pool_hT2 = GraphPool(pool_ratios[2], gat_dims[1], 0.3)\n\n        self.out_layer = nn.Linear(5 * gat_dims[1], 2)\n\n    def forward(self, x, Freq_aug=False):\n\n        x = x.unsqueeze(1)\n        x = self.conv_time(x, mask=Freq_aug)\n        x = x.unsqueeze(dim=1)\n        x = F.max_pool2d(torch.abs(x), (3, 3))\n        x = self.first_bn(x)\n        x = self.selu(x)\n\n        # get embeddings using encoder\n        # (#bs, #filt, #spec, #seq)\n        e = self.encoder(x)\n\n        # spectral GAT (GAT-S)\n        e_S, _ = torch.max(torch.abs(e), dim=3)  # max along time\n        e_S = e_S.transpose(1, 2) + self.pos_S\n\n        gat_S = self.GAT_layer_S(e_S)\n        out_S = self.pool_S(gat_S)  # (#bs, #node, #dim)\n\n        # temporal GAT (GAT-T)\n        e_T, _ = torch.max(torch.abs(e), dim=2)  # max along freq\n        e_T = e_T.transpose(1, 2)\n\n        gat_T = self.GAT_layer_T(e_T)\n        out_T = self.pool_T(gat_T)\n\n        # learnable master node\n        master1 = self.master1.expand(x.size(0), -1, -1)\n        master2 = self.master2.expand(x.size(0), -1, -1)\n\n        # inference 1\n        out_T1, out_S1, master1 = self.HtrgGAT_layer_ST11(\n            out_T, out_S, master=self.master1)\n\n        out_S1 = self.pool_hS1(out_S1)\n        out_T1 = self.pool_hT1(out_T1)\n\n        out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST12(\n            out_T1, out_S1, master=master1)\n        out_T1 = out_T1 + out_T_aug\n        out_S1 = out_S1 + out_S_aug\n        master1 = master1 + master_aug\n\n        # inference 2\n        out_T2, out_S2, master2 = self.HtrgGAT_layer_ST21(\n            out_T, out_S, master=self.master2)\n        out_S2 = self.pool_hS2(out_S2)\n        out_T2 = self.pool_hT2(out_T2)\n\n        out_T_aug, out_S_aug, master_aug = self.HtrgGAT_layer_ST22(\n            out_T2, out_S2, master=master2)\n        out_T2 = out_T2 + out_T_aug\n        out_S2 = out_S2 + out_S_aug\n        master2 = master2 + master_aug\n\n        out_T1 = self.drop_way(out_T1)\n        out_T2 = self.drop_way(out_T2)\n        out_S1 = self.drop_way(out_S1)\n        out_S2 = self.drop_way(out_S2)\n        master1 = self.drop_way(master1)\n        master2 = self.drop_way(master2)\n\n        out_T = torch.max(out_T1, out_T2)\n        out_S = torch.max(out_S1, out_S2)\n        master = torch.max(master1, master2)\n\n        T_max, _ = torch.max(torch.abs(out_T), dim=1)\n        T_avg = torch.mean(out_T, dim=1)\n\n        S_max, _ = torch.max(torch.abs(out_S), dim=1)\n        S_avg = torch.mean(out_S, dim=1)\n\n        last_hidden = torch.cat(\n            [T_max, T_avg, S_max, S_avg, master.squeeze(1)], dim=1)\n\n        last_hidden = self.drop(last_hidden)\n        output = self.out_layer(last_hidden)\n\n        return last_hidden, output\n\n    def pad(self, x, max_len=64600): # 64600 samples = 4 giây\n      x_len = x.shape[0]\n      if x_len >= max_len:\n          return x[:max_len]\n      # need to pad\n      num_repeats = int(max_len / x_len) + 1\n      padded_x = np.tile(x, (1, num_repeats))[:, :max_len][0]\n      return padded_x\n\n    def getScore(self, path_file_test: Path | str):\n      x, _ = soundfile.read(path_file_test)\n      x_pad = self.pad(x)\n      x_inp = Tensor(x_pad)\n      x_inp = torch.unsqueeze(x_inp, 0).to(device)\n      self.eval()\n      with torch.no_grad():\n            last_hidden, output = self.forward(x_inp)\n      scores = F.softmax(output) ### có 2 score ??? lấy thế nào --> lấy cái điểm đánh giá x không phải spoof, là real\n\n#       print(scores[0])\n      return scores[0][1].detach().cpu().numpy()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Load Model","metadata":{}},{"cell_type":"code","source":"from safetensors.torch import load_file\nimport torch\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"r48 = ResNet48_ASV().to(device)\nstate_dict = load_file(\"/kaggle/input/model-final/final_resnet48asv_50k.safetensors\")\nr48.load_state_dict(state_dict)\nr48.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T11:27:39.503257Z","iopub.execute_input":"2025-08-11T11:27:39.504058Z","iopub.status.idle":"2025-08-11T11:27:40.341230Z","shell.execute_reply.started":"2025-08-11T11:27:39.504032Z","shell.execute_reply":"2025-08-11T11:27:40.340286Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"ResNet48_ASV(\n  (conv1): Conv2d(1, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n  (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (2): BasicBlock(\n      (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (3): BasicBlock(\n      (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (4): BasicBlock(\n      (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (5): BasicBlock(\n      (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(96, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(96, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (2): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (3): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (4): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (5): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (6): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (7): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 160, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (2): BasicBlock(\n      (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (3): BasicBlock(\n      (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (4): BasicBlock(\n      (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (5): BasicBlock(\n      (conv1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(160, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(160, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (2): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (pooling): StatsPooling()\n  (fc): Linear(in_features=5120, out_features=256, bias=True)\n)"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"aasist = AASIST_Model().to(device)\naasist.load_state_dict(torch.load(\"/kaggle/input/model-final/aasist.pth\"))\naasist.eval()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Processing","metadata":{}},{"cell_type":"code","source":"!pip install webrtcvad","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T11:27:44.300397Z","iopub.execute_input":"2025-08-11T11:27:44.301099Z","iopub.status.idle":"2025-08-11T11:27:52.484327Z","shell.execute_reply.started":"2025-08-11T11:27:44.301068Z","shell.execute_reply":"2025-08-11T11:27:52.483330Z"}},"outputs":[{"name":"stdout","text":"Collecting webrtcvad\n  Downloading webrtcvad-2.0.10.tar.gz (66 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.2/66.2 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nBuilding wheels for collected packages: webrtcvad\n  Building wheel for webrtcvad (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for webrtcvad: filename=webrtcvad-2.0.10-cp311-cp311-linux_x86_64.whl size=73499 sha256=728961e2df65f88d731e61183ed649dbdf171bfcebeaecb2afffe9371f0635e9\n  Stored in directory: /root/.cache/pip/wheels/94/65/3f/292d0b656be33d1c801831201c74b5f68f41a2ae465ff2ee2f\nSuccessfully built webrtcvad\nInstalling collected packages: webrtcvad\nSuccessfully installed webrtcvad-2.0.10\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"## Remove Silence\n","metadata":{}},{"cell_type":"code","source":"import webrtcvad\ndef remove_silence(waveform, sample_rate=16000, frame_duration_ms=30):\n    vad = webrtcvad.Vad(2)  # Moderate aggressiveness (0-3)\n    waveform_np = waveform.squeeze().numpy()\n    waveform_int16 = (waveform_np * 32767).astype(np.int16)\n    frame_length = int(sample_rate * frame_duration_ms / 1000)\n    frames = [waveform_int16[i:i+frame_length] for i in range(0, len(waveform_int16), frame_length)]\n    \n    voiced_frames = []\n    for frame in frames:\n        if len(frame) == frame_length and vad.is_speech(frame.tobytes(), sample_rate):\n            voiced_frames.append(frame)\n    \n    if voiced_frames:\n        voiced_waveform = np.concatenate(voiced_frames).astype(np.float32) / 32767\n        return torch.tensor(voiced_waveform, dtype=torch.float32).unsqueeze(0)\n    return waveform","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T11:27:52.486059Z","iopub.execute_input":"2025-08-11T11:27:52.486314Z","iopub.status.idle":"2025-08-11T11:27:52.575998Z","shell.execute_reply.started":"2025-08-11T11:27:52.486290Z","shell.execute_reply":"2025-08-11T11:27:52.575293Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"def extract_mfbe(waveform, sample_rate=16000, n_mels=80):\n    # Tính Mel spectrogram\n    mel_spec = torchaudio.transforms.MelSpectrogram(\n        sample_rate=sample_rate,\n        n_fft=400,\n        win_length=400,\n        hop_length=160,\n        n_mels=n_mels,\n        power=2.0\n    )(waveform)\n\n    # Convert sang log-mel-filterbank energy\n    mfbe = torch.log(mel_spec + 1e-6)\n    return mfbe","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T11:27:52.576872Z","iopub.execute_input":"2025-08-11T11:27:52.577088Z","iopub.status.idle":"2025-08-11T11:27:52.581397Z","shell.execute_reply.started":"2025-08-11T11:27:52.577072Z","shell.execute_reply":"2025-08-11T11:27:52.580671Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"# Get Embedding","metadata":{}},{"cell_type":"markdown","source":"## ASV Embed Function\n","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nimport torchaudio\nimport numpy as np\n\ndef get_asv_score(\n    wav_path, model, device=\"cuda\",\n    crop_duration=2, sr=16000, hop_ratio=0.5, full_dur=5,\n    sliding_weight=0.7\n):\n    # 1) load -> resample -> mono\n    waveform, sr_orig = torchaudio.load(wav_path)            # [C, T]\n    if sr_orig != sr:\n        waveform = torchaudio.functional.resample(waveform, sr_orig, sr)\n    if waveform.shape[0] > 1:\n        waveform = waveform.mean(dim=0, keepdim=True)        # [1, T]\n    waveform = remove_silence(waveform, sample_rate=sr)\n    if waveform.dim() == 1:\n        waveform = waveform.unsqueeze(0)                     # [1, T]\n    waveform = waveform.float()\n\n    # 2) tạo crops 2s\n    nb_samp = int(crop_duration * sr)\n    hop = max(1, int(nb_samp * hop_ratio))\n    T = waveform.shape[1]\n    crops = []\n    if T <= nb_samp:\n        pad = nb_samp - T\n        crops.append(F.pad(waveform, (0, pad)))              # [1, nb_samp]\n    else:\n        for s in range(0, T - nb_samp + 1, hop):\n            crops.append(waveform[:, s:s+nb_samp])           # [1, nb_samp]\n        if (T - nb_samp) % hop != 0:\n            crops.append(waveform[:, -nb_samp:])\n\n    # 3) MFBE cho TẤT CẢ crop -> batch [S,1,F,T]\n    feats = []\n    for c in crops:\n        f = extract_mfbe(c, sample_rate=sr)                  # [F, Tm] hoặc [1,F,Tm]\n        if f.dim() == 2:\n            f = f.unsqueeze(0)                               # -> [1, F, Tm]\n        elif f.dim() == 3 and f.size(0) == 1:\n            pass                                             # đã [1,F,Tm]\n        else:\n            raise RuntimeError(f\"Unexpected feature shape: {tuple(f.shape)}\")\n        feats.append(f)\n\n    # cắt về cùng Tm để stack\n    Tm = min(fe.shape[2] for fe in feats)                    # chú ý: feats là [1,F,T]\n    feats = [fe[:, :, :Tm] for fe in feats]                  # giữ C=1\n    batch = torch.stack(feats, dim=0).to(device)             # [S, 1, F, Tm]  ✅ đúng trật tự\n    # KHÔNG unsqueeze(0) nữa! (sẽ thành [1,S,F,T])\n\n    # 4) forward 1 lần + L2 -> mean -> L2\n    model.eval()\n    with torch.inference_mode():\n        try:\n            out = model(batch, aug=False)                    # nếu model có 'aug'\n        except TypeError:\n            out = model(batch)\n        emb_batch = out[0] if isinstance(out, (tuple, list)) else out  # [S, D]\n\n    emb = F.normalize(emb_batch, dim=-1).mean(dim=0)         # L2 từng crop rồi mean\n    emb = F.normalize(emb, dim=-1)\n    return emb.detach().cpu().numpy().astype(np.float32)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T11:31:37.161657Z","iopub.execute_input":"2025-08-11T11:31:37.162368Z","iopub.status.idle":"2025-08-11T11:31:37.173963Z","shell.execute_reply.started":"2025-08-11T11:31:37.162346Z","shell.execute_reply":"2025-08-11T11:31:37.173245Z"}},"outputs":[],"execution_count":22},{"cell_type":"markdown","source":"## CM Embed Function","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nimport torchaudio\nimport numpy as np\n\ndef get_cm_score(wav_path, model, device=\"cuda\",\n                 nb_samp=64600, use_overlay=True, hop_ratio=0.5):\n    wav, sr = torchaudio.load(wav_path)             # [C, T]\n    if sr != 16000:\n        wav = torchaudio.functional.resample(wav, sr, 16000)\n    if wav.shape[0] > 1:\n        wav = wav.mean(dim=0, keepdim=True)         # [1, T]\n\n    T = wav.shape[1]\n    crops = []\n\n    if not use_overlay:\n        # CENTER-CROP (pad cân 2 đầu nếu ngắn)\n        if T < nb_samp:\n            pad = nb_samp - T\n            left = pad // 2; right = pad - left\n            wav = F.pad(wav, (left, right))\n        else:\n            start = (T - nb_samp) // 2\n            wav = wav[:, start:start+nb_samp]\n        crops = [wav]                                # 1 crop\n    else:\n        # OVERLAY 4s + mean\n        hop = max(1, int(nb_samp * hop_ratio))\n        if T <= nb_samp:\n            pad = nb_samp - T\n            left = pad // 2; right = pad - left\n            crops = [F.pad(wav, (left, right))]\n        else:\n            for s in range(0, T - nb_samp + 1, hop):\n                crops.append(wav[:, s:s+nb_samp])\n            if (T - nb_samp) % hop != 0:\n                crops.append(wav[:, -nb_samp:])      # phủ đuôi\n\n    # AASIST thường nhận [B, T]; nếu model bạn cần [B,1,T], thêm .unsqueeze(1)\n    batch = torch.stack([c.squeeze(0) for c in crops], dim=0).to(device)  # [S, T]\n    model.eval()\n    with torch.inference_mode():\n        out = model(batch)                           # -> (emb, logits) hoặc emb\n        if isinstance(out, (tuple, list)):\n            emb_batch, logits = out[0], out[1]      # [S, D], [S, C] (hoặc [S])\n        else:\n            emb_batch, logits = out, None\n\n    # ===== CM score: mean LOGIT rồi sigmoid (ổn định hơn mean prob) =====\n    cm_score = None\n    if logits is not None:\n        if logits.dim() == 2 and logits.size(1) >= 2:\n            spoof_logit = logits[:, 1].mean()\n            cm_score = torch.sigmoid(spoof_logit).item()\n        else:\n            # 1D logit\n            cm_score = torch.sigmoid(logits.mean()).item()\n\n    # ===== Embedding pooling: L2 -> mean -> L2 =====\n    emb = F.normalize(emb_batch, dim=-1).mean(dim=0)\n    emb = F.normalize(emb, dim=-1).detach().cpu().numpy().astype(np.float32)\n\n    return emb, cm_score if cm_score is not None else 0.0","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Train Embed","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nfrom tqdm import tqdm\n\n# 1. Load danh sách speaker đã train\ntrain_speakers = set()\nwith open(\"/kaggle/input/log-training-eca-aasist/train.txt\", \"r\") as f:\n    for line in f:\n        spk = line.strip().split()[0]\n        train_speakers.add(spk)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T11:23:57.794398Z","iopub.execute_input":"2025-08-11T11:23:57.794770Z","iopub.status.idle":"2025-08-11T11:23:58.034743Z","shell.execute_reply.started":"2025-08-11T11:23:57.794740Z","shell.execute_reply":"2025-08-11T11:23:58.033879Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"root_dir = \"/kaggle/input/vsasv-train/vlsp_train/home4/vuhl/VSASV-Dataset/vlsp2025/train\"\nout_root_asv = \"r48_embeddings_train\"\nout_root_cm = \"aasist_embeddings_train\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T11:23:58.036058Z","iopub.execute_input":"2025-08-11T11:23:58.036421Z","iopub.status.idle":"2025-08-11T11:23:58.040594Z","shell.execute_reply.started":"2025-08-11T11:23:58.036394Z","shell.execute_reply":"2025-08-11T11:23:58.039692Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"os.makedirs(out_root_asv, exist_ok=True)\nos.makedirs(out_root_cm, exist_ok=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tqdm import tqdm\nimport os\n\nall_wavs = []\nfor dirpath, dirnames, filenames in tqdm(os.walk(root_dir),\n                                        desc=\"Scanning folders\",\n                                        unit=\"dir\"):\n    for fname in filenames:\n        if not fname.lower().endswith((\".wav\", \".flac\")):\n            continue\n        rel_path = os.path.relpath(dirpath, root_dir)  # e.g. \"id00016/bonafide\"\n        speaker_id = rel_path.split(os.sep)[0]\n        if speaker_id in train_speakers:\n            continue\n        rel_file = os.path.join(rel_path, fname)\n        all_wavs.append(rel_file)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T11:27:55.605777Z","iopub.execute_input":"2025-08-11T11:27:55.606391Z","iopub.status.idle":"2025-08-11T11:28:36.249242Z","shell.execute_reply.started":"2025-08-11T11:27:55.606369Z","shell.execute_reply":"2025-08-11T11:28:36.248469Z"}},"outputs":[{"name":"stderr","text":"Scanning folders: 2245dir [00:40, 55.25dir/s]\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"from tqdm import tqdm\nimport os\n\n\n# 3. Duyệt thư mục đệ quy với tqdm\nall_wavs = []\nfor dirpath, dirnames, filenames in tqdm(os.walk(root_dir),\n                                        desc=\"Scanning directories\",\n                                        unit=\"dir\"):\n    for fname in filenames:\n        if not fname.lower().endswith((\".wav\", \".flac\")):\n            continue\n        rel_path = os.path.relpath(dirpath, root_dir)  # e.g. \"id00016/bonafide\"\n        speaker_id = rel_path.split(os.sep)[0]\n        if speaker_id in train_speakers:\n            continue\n        rel_file = os.path.join(rel_path, fname)\n        all_wavs.append(rel_file)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T11:26:20.424947Z","iopub.execute_input":"2025-08-11T11:26:20.425230Z","iopub.status.idle":"2025-08-11T11:27:01.183481Z","shell.execute_reply.started":"2025-08-11T11:26:20.425202Z","shell.execute_reply":"2025-08-11T11:27:01.182619Z"}},"outputs":[{"name":"stderr","text":"Scanning directories: 2245dir [00:40, 55.09dir/s] \n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"for wav_rel in tqdm(all_wavs, desc=\"Extract ASV Score\"):\n    full_path = os.path.join(root_dir, wav_rel)\n    if not os.path.exists(full_path):\n        print(f\"[WARN] File not found: {full_path}\")\n        continue\n\n    embedding = get_asv_score(full_path, model=r48, device=\"cuda\")\n\n    # 4.1 Xác định đường dẫn output dựa trên rel_path\n    rel_no_ext, _ = os.path.splitext(wav_rel)\n    out_path = os.path.join(out_root_asv, rel_no_ext + \".npy\")\n\n    # 4.2 Tạo các thư mục con nếu cần\n    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n\n    # 4.3 Lưu embedding\n    np.save(out_path, embedding)\n\n\nprint(\"Done! Đã lưu embedding theo rel_path trong thư mục r48_embeddings_train/\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T11:31:42.045391Z","iopub.execute_input":"2025-08-11T11:31:42.046158Z","iopub.status.idle":"2025-08-11T11:53:17.803673Z","shell.execute_reply.started":"2025-08-11T11:31:42.046132Z","shell.execute_reply":"2025-08-11T11:53:17.802775Z"}},"outputs":[{"name":"stderr","text":"Extract ASV Score: 100%|██████████| 18717/18717 [21:35<00:00, 14.44it/s]","output_type":"stream"},{"name":"stdout","text":"Done! Đã lưu embedding theo rel_path trong thư mục r48_embeddings_train/\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"import os, json\nimport numpy as np\nfrom tqdm import tqdm\n\ncm_scores = {}  # uid (hoặc rel path không đuôi) -> score\n\nfor wav_rel in tqdm(all_wavs, desc=\"Extract CM Score\"):\n    full_path = os.path.join(root_dir, wav_rel)\n    if not os.path.exists(full_path):\n        print(f\"[WARN] File not found: {full_path}\")\n        continue\n\n    # get_cm_score trả (embedding, score)\n    emb, score = get_cm_score(full_path, model=aasist, device=\"cuda\")\n\n    # 4.1 Xác định đường dẫn output dựa trên rel_path\n    rel_no_ext, _ = os.path.splitext(wav_rel)\n    out_path = os.path.join(out_root_cm, rel_no_ext + \".npy\")\n\n    # 4.2 Tạo các thư mục con nếu cần\n    os.makedirs(os.path.dirname(out_root_cm), exist_ok=True)\n\n    # 4.3 Lưu embedding (đảm bảo float32 1D)\n    emb = np.asarray(emb, dtype=np.float32).reshape(-1)\n    np.save(out_root_cm, emb)\n\n    # 4.4 Lưu score vào dict (dùng rel path không đuôi làm key)\n    cm_scores[rel_no_ext] = float(score)\n\n# 5) Dump JSON\njson_path = os.path.join(\"aasist_scores_train.json\")\nwith open(json_path, \"w\", encoding=\"utf-8\") as f:\n    json.dump(cm_scores, f, ensure_ascii=False, indent=2, sort_keys=True)\n\nprint(f\"Done! Saved embeddings under '{out_root}' and CM scores to '{json_path}'.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import zipfile\n\nOUTPUT_DIR = \"/kaggle/working/r48_embeddings_train\"\nZIP_NAME = f\"/kaggle/working/r48_embeddings_train.zip\"\n\nwith zipfile.ZipFile(ZIP_NAME, 'w', zipfile.ZIP_DEFLATED) as zipf:\n    for root, _, files in os.walk(OUTPUT_DIR):\n        for file in files:\n            file_path = os.path.join(root, file)\n            arcname = os.path.relpath(file_path, OUTPUT_DIR)\n\n            # Thêm file vào zip\n            zipf.write(file_path, arcname)\n\n            # Xoá file sau khi đã nén xong\n            os.remove(file_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T11:53:17.805049Z","iopub.execute_input":"2025-08-11T11:53:17.805288Z","iopub.status.idle":"2025-08-11T11:53:21.294323Z","shell.execute_reply.started":"2025-08-11T11:53:17.805265Z","shell.execute_reply":"2025-08-11T11:53:21.293729Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"import zipfile\n\nOUTPUT_DIR = \"/kaggle/working/aasist_embeddings_train\"\nZIP_NAME = f\"/kaggle/working/aasist_embeddings_train.zip\"\n\nwith zipfile.ZipFile(ZIP_NAME, 'w', zipfile.ZIP_DEFLATED) as zipf:\n    for root, _, files in os.walk(OUTPUT_DIR):\n        for file in files:\n            file_path = os.path.join(root, file)\n            arcname = os.path.relpath(file_path, OUTPUT_DIR)\n\n            # Thêm file vào zip\n            zipf.write(file_path, arcname)\n\n            # Xoá file sau khi đã nén xong\n            os.remove(file_path)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Public Test Embed","metadata":{}},{"cell_type":"code","source":"root_dir = \"/kaggle/input/public-test-vsasv/public_test/home4/vuhl/VSASV-Dataset/vlsp2025/\"\nlist_path = \"/kaggle/input/public-test-vsasv/public_test_vlsp.txt\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T11:53:21.295108Z","iopub.execute_input":"2025-08-11T11:53:21.295390Z","iopub.status.idle":"2025-08-11T11:53:21.299068Z","shell.execute_reply.started":"2025-08-11T11:53:21.295364Z","shell.execute_reply":"2025-08-11T11:53:21.298294Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"trials = []\nwith open(list_path, \"r\") as f:\n    for line in f:\n        enroll, test, _ = line.strip().split()\n        trials.append((enroll, test))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T11:53:21.300692Z","iopub.execute_input":"2025-08-11T11:53:21.301156Z","iopub.status.idle":"2025-08-11T11:53:21.813185Z","shell.execute_reply.started":"2025-08-11T11:53:21.301137Z","shell.execute_reply":"2025-08-11T11:53:21.812609Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"all_wavs = set()\nfor path1, path2 in trials:\n    all_wavs.add(path1)\n    all_wavs.add(path2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T11:53:21.813898Z","iopub.execute_input":"2025-08-11T11:53:21.814086Z","iopub.status.idle":"2025-08-11T11:53:21.966200Z","shell.execute_reply.started":"2025-08-11T11:53:21.814071Z","shell.execute_reply":"2025-08-11T11:53:21.965638Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"from tqdm import tqdm\nimport os\nos.makedirs(\"aasist_embedding_pub\", exist_ok=True)\n\ncm_score = {}\nfor wav_path in tqdm(all_wavs, desc=\"Extract CM Score\"):\n    full_path = os.path.join(root_dir, wav_path)\n    if not os.path.exists(full_path):\n        print(f\"File not found {full_path}\")\n        continue\n\n    embedding, score = get_cm_score(full_path, aasist)\n    # Lưu embedding\n    uid = os.path.splitext(os.path.basename(wav_path))[0]\n    np.save(f\"aasist_embedding_pub/{uid}.npy\", embedding)\n\n    # Lưu score\n    cm_score[wav_path] = score","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\nwith open(\"aasist_score_pub.json\", \"w\") as f:\n    json.dump(cm_score, f, indent=2)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import zipfile\n\nOUTPUT_DIR = \"/kaggle/working/aasist_embedding_pub\"\nZIP_NAME = f\"/kaggle/working/aasist_embedding_pub.zip\"\n\nwith zipfile.ZipFile(ZIP_NAME, 'w', zipfile.ZIP_DEFLATED) as zipf:\n    for root, _, files in os.walk(OUTPUT_DIR):\n        for file in files:\n            file_path = os.path.join(root, file)\n            arcname = os.path.relpath(file_path, OUTPUT_DIR)\n\n            # Thêm file vào zip\n            zipf.write(file_path, arcname)\n\n            # Xoá file sau khi đã nén xong\n            os.remove(file_path)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tqdm import tqdm\nimport os\nos.makedirs(\"r48_embedding_pub\", exist_ok=True)\n\n\nfor wav_path in tqdm(all_wavs, desc=\"Extract ASV Score\"):\n    full_path = os.path.join(root_dir, wav_path)\n    if not os.path.exists(full_path):\n        print(f\"File not found {full_path}\")\n        continue\n\n    embedding = get_asv_score(full_path, r48)\n    # Lưu embedding\n    uid = os.path.splitext(os.path.basename(wav_path))[0]\n    np.save(f\"r48_embedding_pub/{uid}.npy\", embedding)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T11:53:33.701517Z","iopub.execute_input":"2025-08-11T11:53:33.701806Z","iopub.status.idle":"2025-08-11T12:47:26.655346Z","shell.execute_reply.started":"2025-08-11T11:53:33.701785Z","shell.execute_reply":"2025-08-11T12:47:26.654553Z"}},"outputs":[{"name":"stderr","text":"Extract CM Score: 100%|██████████| 73614/73614 [53:52<00:00, 22.77it/s]  \n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"import zipfile\n\nOUTPUT_DIR = \"/kaggle/working/r48_embedding_pub\"\nZIP_NAME = f\"/kaggle/working/r48_embedding_pub.zip\"\n\nwith zipfile.ZipFile(ZIP_NAME, 'w', zipfile.ZIP_DEFLATED) as zipf:\n    for root, _, files in os.walk(OUTPUT_DIR):\n        for file in files:\n            file_path = os.path.join(root, file)\n            arcname = os.path.relpath(file_path, OUTPUT_DIR)\n\n            # Thêm file vào zip\n            zipf.write(file_path, arcname)\n\n            # Xoá file sau khi đã nén xong\n            os.remove(file_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T12:47:26.656864Z","iopub.execute_input":"2025-08-11T12:47:26.657126Z","iopub.status.idle":"2025-08-11T12:47:40.612292Z","shell.execute_reply.started":"2025-08-11T12:47:26.657106Z","shell.execute_reply":"2025-08-11T12:47:40.611537Z"}},"outputs":[],"execution_count":30},{"cell_type":"markdown","source":"## Private Test Embed","metadata":{}},{"cell_type":"code","source":"root_dir = \"/kaggle/input/private-test-vlsp/private_test/home4/vuhl/VSASV-Dataset/vlsp2025/\"\nlist_path = \"/kaggle/input/private-test-vlsp/private_test_vlsp.txt\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T12:47:40.613150Z","iopub.execute_input":"2025-08-11T12:47:40.613540Z","iopub.status.idle":"2025-08-11T12:47:40.617364Z","shell.execute_reply.started":"2025-08-11T12:47:40.613515Z","shell.execute_reply":"2025-08-11T12:47:40.616680Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"trials = []\nwith open(list_path, \"r\") as f:\n    for line in f:\n        enroll, test= line.strip().split()\n        trials.append((enroll, test))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T12:47:56.108951Z","iopub.execute_input":"2025-08-11T12:47:56.109210Z","iopub.status.idle":"2025-08-11T12:47:56.762073Z","shell.execute_reply.started":"2025-08-11T12:47:56.109191Z","shell.execute_reply":"2025-08-11T12:47:56.761464Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"all_wavs = set()\nfor path1, path2 in trials:\n    all_wavs.add(path1)\n    all_wavs.add(path2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T12:47:58.430309Z","iopub.execute_input":"2025-08-11T12:47:58.431012Z","iopub.status.idle":"2025-08-11T12:47:58.608475Z","shell.execute_reply.started":"2025-08-11T12:47:58.430989Z","shell.execute_reply":"2025-08-11T12:47:58.607708Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"from tqdm import tqdm\nimport os\nos.makedirs(\"aasist_embedding_private\", exist_ok=True)\n\ncm_score = {}\nfor wav_path in tqdm(all_wavs, desc=\"Extract CM Score\"):\n    full_path = os.path.join(root_dir, wav_path)\n    if not os.path.exists(full_path):\n        print(f\"File not found {full_path}\")\n        continue\n\n    embedding, score = get_cm_score(full_path, aasist)\n    # Lưu embedding\n    uid = os.path.splitext(os.path.basename(wav_path))[0]\n    np.save(f\"aasist_embedding_private/{uid}.npy\", embedding)\n\n    # Lưu score\n    cm_score[wav_path] = score","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\nwith open(\"aasist_score_private.json\", \"w\") as f:\n    json.dump(cm_score, f, indent=2)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import zipfile\n\nOUTPUT_DIR = \"/kaggle/working/aasist_embedding_private\"\nZIP_NAME = f\"/kaggle/working/aasist_embedding_private.zip\"\n\nwith zipfile.ZipFile(ZIP_NAME, 'w', zipfile.ZIP_DEFLATED) as zipf:\n    for root, _, files in os.walk(OUTPUT_DIR):\n        for file in files:\n            file_path = os.path.join(root, file)\n            arcname = os.path.relpath(file_path, OUTPUT_DIR)\n\n            # Thêm file vào zip\n            zipf.write(file_path, arcname)\n\n            # Xoá file sau khi đã nén xong\n            os.remove(file_path)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tqdm import tqdm\nimport os\nos.makedirs(\"r48_embedding_private\", exist_ok=True)\n\n\nfor wav_path in tqdm(all_wavs, desc=\"Extract ASV Score\"):\n    full_path = os.path.join(root_dir, wav_path)\n    if not os.path.exists(full_path):\n        print(f\"File not found {full_path}\")\n        continue\n\n    embedding = get_asv_score(full_path, r48)\n    # Lưu embedding\n    uid = os.path.splitext(os.path.basename(wav_path))[0]\n    np.save(f\"r48_embedding_private/{uid}.npy\", embedding)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T12:48:00.302560Z","iopub.execute_input":"2025-08-11T12:48:00.303230Z","iopub.status.idle":"2025-08-11T14:08:02.369895Z","shell.execute_reply.started":"2025-08-11T12:48:00.303207Z","shell.execute_reply":"2025-08-11T14:08:02.369122Z"}},"outputs":[{"name":"stderr","text":"Extract CM Score: 100%|██████████| 103417/103417 [1:20:02<00:00, 21.54it/s]\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"from tqdm import tqdm\nimport os\nos.makedirs(\"aasist_embedding_private\", exist_ok=True)\n\ncm_score = {}\nfor wav_path in tqdm(all_wavs, desc=\"Extract CM Score\"):\n    full_path = os.path.join(root_dir, wav_path)\n    if not os.path.exists(full_path):\n        print(f\"File not found {full_path}\")\n        continue\n\n    embedding, score = get_cm_score(full_path, aasist)\n    # Lưu embedding\n    uid = os.path.splitext(os.path.basename(wav_path))[0]\n    np.save(f\"aasist_embedding_private/{uid}.npy\", embedding)\n\n    # Lưu score\n    cm_score[wav_path] = score","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import zipfile\n\nOUTPUT_DIR = \"/kaggle/working/r48_embedding_private\"\nZIP_NAME = f\"/kaggle/working/r48_embedding_private.zip\"\n\nwith zipfile.ZipFile(ZIP_NAME, 'w', zipfile.ZIP_DEFLATED) as zipf:\n    for root, _, files in os.walk(OUTPUT_DIR):\n        for file in files:\n            file_path = os.path.join(root, file)\n            arcname = os.path.relpath(file_path, OUTPUT_DIR)\n\n            # Thêm file vào zip\n            zipf.write(file_path, arcname)\n\n            # Xoá file sau khi đã nén xong\n            os.remove(file_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T14:08:02.371360Z","iopub.execute_input":"2025-08-11T14:08:02.371609Z","iopub.status.idle":"2025-08-11T14:08:22.386093Z","shell.execute_reply.started":"2025-08-11T14:08:02.371588Z","shell.execute_reply":"2025-08-11T14:08:22.385531Z"}},"outputs":[],"execution_count":36}]}