{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d76730c8-4921-4155-b64c-1b6fdc8a046b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.54.1-py3-none-any.whl.metadata (41 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m161.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting filelock (from transformers)\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.34.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.34.3-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2025.7.31-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (53 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.7/53.7 kB\u001b[0m \u001b[31m568.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
      "  Downloading fsspec-2025.7.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.0)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub<1.0,>=0.34.0->transformers)\n",
      "  Downloading hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (879 bytes)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.6.15)\n",
      "Downloading transformers-4.54.1-py3-none-any.whl (11.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/11.2 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.34.3-py3-none-any.whl (558 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m558.8/558.8 kB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2025.7.31-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (804 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m804.5/804.5 kB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Downloading fsspec-2025.7.0-py3-none-any.whl (199 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.6/199.6 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: safetensors, regex, hf-xet, fsspec, filelock, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed filelock-3.18.0 fsspec-2025.7.0 hf-xet-1.1.5 huggingface-hub-0.34.3 regex-2025.7.31 safetensors-0.5.3 tokenizers-0.21.4 transformers-4.54.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c5bfae0-8eff-42af-9295-7490fb3abe6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số thư mục trong data: 816\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Đường dẫn thư mục data\n",
    "path = \"data\"\n",
    "\n",
    "# Đếm số folder con\n",
    "num_dirs = sum(1 for item in os.listdir(path) if os.path.isdir(os.path.join(path, item)))\n",
    "print(\"Số thư mục trong data:\", num_dirs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11e22d51-75ab-4b25-bce8-97076f1db8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tạo file full_path.txt thành công ✅\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "base_dir = \"data\"\n",
    "output_file = \"full_path.txt\"\n",
    "\n",
    "with open(output_file, \"w\") as f:\n",
    "    # Duyệt qua từng speaker folder (idxxxxx)\n",
    "    for speaker in sorted(os.listdir(base_dir)):\n",
    "        speaker_path = os.path.join(base_dir, speaker)\n",
    "        if not os.path.isdir(speaker_path):\n",
    "            continue\n",
    "        \n",
    "        # Duyệt qua nhãn (spoof, bonafide)\n",
    "        for label in [\"spoof\", \"bonafide\"]:\n",
    "            label_path = os.path.join(speaker_path, label)\n",
    "            if not os.path.isdir(label_path):\n",
    "                continue\n",
    "            \n",
    "            # Duyệt qua từng file audio\n",
    "            for wav in sorted(os.listdir(label_path)):\n",
    "                if wav.endswith(\".wav\"):\n",
    "                    rel_path = os.path.join(speaker, label, wav)  # relative path\n",
    "                    line = f\"{speaker} {rel_path} {label}\\n\"\n",
    "                    f.write(line)\n",
    "\n",
    "print(f\"Tạo file {output_file} thành công ✅\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "762fec37-0b12-4bfc-a186-7caa87701e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "\n",
    "def make_train_val_pairs(all_file, train_file=\"train.txt\", val_file=\"val.txt\", val_pairs_file=\"val_pairs.txt\",\n",
    "                         split_ratio=0.8, max_pairs=50000, seed=42):\n",
    "    random.seed(seed)\n",
    "\n",
    "    # B1: Gom file theo speaker, chỉ lấy bonafide (label == \"0\")\n",
    "    speaker2lines = defaultdict(list)\n",
    "    with open(all_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            spk, path, label = line.strip().split()\n",
    "            if label == \"bonafide\":  # chỉ giữ bonafide\n",
    "                speaker2lines[spk].append((spk, path, label))\n",
    "\n",
    "    speakers = list(speaker2lines.keys())\n",
    "    random.shuffle(speakers)\n",
    "\n",
    "    # B2: Chia speaker train/val\n",
    "    n_train = int(len(speakers) * split_ratio)\n",
    "    train_speakers = set(speakers[:n_train])\n",
    "    val_speakers = set(speakers[n_train:])\n",
    "\n",
    "    # B3: Xuất train.txt và val.txt (val chỉ giữ file chứa \"orig\")\n",
    "    with open(train_file, \"w\") as f_train, open(val_file, \"w\") as f_val:\n",
    "        for spk in train_speakers:\n",
    "            for entry in speaker2lines[spk]:\n",
    "                f_train.write(\" \".join(entry) + \"\\n\")\n",
    "        for spk in val_speakers:\n",
    "            for entry in speaker2lines[spk]:\n",
    "                if \"orig\" in entry[1]:  # chỉ lấy file có 'orig' trong tên\n",
    "                    f_val.write(\" \".join(entry) + \"\\n\")\n",
    "\n",
    "    print(f\"✅ Train: {len(train_speakers)} speakers → {train_file}\")\n",
    "    print(f\"✅ Val:   {len(val_speakers)} speakers (only bonafide 'orig' files) → {val_file}\")\n",
    "\n",
    "    # B4: Sinh val pairs (giới hạn 20k cặp, chỉ bonafide)\n",
    "    val_files_by_spk = {spk: [path for _, path, _ in lines if \"orig\" in path]\n",
    "                        for spk, lines in speaker2lines.items() if spk in val_speakers}\n",
    "    val_speakers_list = [spk for spk, files in val_files_by_spk.items() if len(files) > 0]\n",
    "\n",
    "    # Positive pairs\n",
    "    pos_pairs = []\n",
    "    for spk, files in val_files_by_spk.items():\n",
    "        if len(files) < 2:\n",
    "            continue\n",
    "        pos_pairs.extend([(f1, f2, 1) for f1, f2 in itertools.combinations(files, 2)])\n",
    "\n",
    "    random.shuffle(pos_pairs)\n",
    "    n_pos = min(len(pos_pairs), max_pairs // 2)  # 10k positive\n",
    "    val_pairs = pos_pairs[:n_pos]\n",
    "\n",
    "    # Negative pairs\n",
    "    n_neg = n_pos\n",
    "    while len(val_pairs) < n_pos + n_neg and len(val_speakers_list) >= 2:\n",
    "        spk1, spk2 = random.sample(val_speakers_list, 2)\n",
    "        f1 = random.choice(val_files_by_spk[spk1])\n",
    "        f2 = random.choice(val_files_by_spk[spk2])\n",
    "        val_pairs.append((f1, f2, 0))\n",
    "\n",
    "    random.shuffle(val_pairs)\n",
    "\n",
    "    # Xuất val_pairs.txt\n",
    "    with open(val_pairs_file, \"w\") as f:\n",
    "        for f1, f2, label in val_pairs:\n",
    "            f.write(f\"{f1} {f2} {label}\\n\")\n",
    "\n",
    "    print(f\"✅ Val pairs: {len(val_pairs)} (≈{n_pos} pos + {n_neg} neg, only bonafide) → {val_pairs_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e7f3e00-8c91-4332-969c-1fc4b528b43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Train: 652 speakers → train.txt\n",
      "✅ Val:   163 speakers (only bonafide 'orig' files) → val.txt\n",
      "✅ Val pairs: 50000 (≈25000 pos + 25000 neg, only bonafide) → val_pairs.txt\n"
     ]
    }
   ],
   "source": [
    "make_train_val_pairs(\"full_path.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Số speaker còn lại sau khi loại ASV: 163\n",
      "✅ Đã sinh 336913 target pairs\n",
      "✅ Đã sinh 336913 nontarget pairs\n",
      "✅ Đã sinh 529603 spoof pairs\n",
      "▶ Target: 336913\n",
      "▶ Nontarget: 336913\n",
      "▶ Spoof: 529603\n",
      "▶ Tổng cộng: 1203429\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "# === 1. Load ASV speaker IDs đã dùng (loại bỏ khỏi cohort) ===\n",
    "asv_ids = set()\n",
    "with open(\"./path_list/train_asv.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        spk_id = line.strip().split()[0]\n",
    "        asv_ids.add(spk_id)\n",
    "\n",
    "# === 2. Load metadata và tách bonafide / spoof ===\n",
    "spk2bonafide = defaultdict(list)\n",
    "spk2spoof = defaultdict(list)\n",
    "\n",
    "with open(\"./path_list/train_vlsp_2025_metadata.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        spk, path, label = line.strip().split()\n",
    "        if spk in asv_ids:\n",
    "            continue\n",
    "        if label == \"bonafide\":\n",
    "            spk2bonafide[spk].append(path)\n",
    "        elif label == \"spoof\":\n",
    "            spk2spoof[spk].append(path)\n",
    "\n",
    "speakers = list(spk2bonafide.keys())\n",
    "print(f\"✅ Số speaker còn lại sau khi loại ASV: {len(speakers)}\")\n",
    "\n",
    "output_file = \"sasv_binary_trials_3labels.txt\"\n",
    "\n",
    "# === 3. Tạo target trials (cùng speaker, đều bonafide) ===\n",
    "target_goal = 500000\n",
    "max_enroll_usage_target = 30\n",
    "enroll_usage_target = Counter()\n",
    "target_count = 0\n",
    "\n",
    "with open(output_file, \"w\") as f:\n",
    "    for spk in speakers:\n",
    "        utts = spk2bonafide[spk]\n",
    "        if len(utts) < 2:\n",
    "            continue\n",
    "\n",
    "        pairs = [(a, b) for i, a in enumerate(utts) for b in utts[i + 1:]]\n",
    "        random.shuffle(pairs)\n",
    "\n",
    "        for a, b in pairs:\n",
    "            if enroll_usage_target[a] >= max_enroll_usage_target:\n",
    "                continue\n",
    "            f.write(f\"{a} {b} target\\n\")\n",
    "            enroll_usage_target[a] += 1\n",
    "            target_count += 1\n",
    "            if target_count >= target_goal:\n",
    "                break\n",
    "        if target_count >= target_goal:\n",
    "            break\n",
    "\n",
    "print(f\"✅ Đã sinh {target_count} target pairs\")\n",
    "\n",
    "# === 4. Nontarget trials (khác speaker, đều bonafide) ===\n",
    "required_nontarget = target_count  # bạn có thể set tỉ lệ khác nếu muốn\n",
    "nontarget_count = 0\n",
    "max_enroll_usage_nt = 15\n",
    "enroll_usage_nontarget = Counter()\n",
    "\n",
    "with open(output_file, \"a\") as f:\n",
    "    for i in range(len(speakers)):\n",
    "        for j in range(i + 1, len(speakers)):\n",
    "            u1_list = spk2bonafide[speakers[i]]\n",
    "            u2_list = spk2bonafide[speakers[j]]\n",
    "            random.shuffle(u1_list)\n",
    "            random.shuffle(u2_list)\n",
    "            for u1 in u1_list:\n",
    "                if enroll_usage_nontarget[u1] >= max_enroll_usage_nt:\n",
    "                    continue\n",
    "                for u2 in u2_list:\n",
    "                    f.write(f\"{u1} {u2} nontarget\\n\")\n",
    "                    enroll_usage_nontarget[u1] += 1\n",
    "                    nontarget_count += 1\n",
    "                    if nontarget_count >= required_nontarget:\n",
    "                        break\n",
    "                if nontarget_count >= required_nontarget:\n",
    "                    break\n",
    "            if nontarget_count >= required_nontarget:\n",
    "                break\n",
    "        if nontarget_count >= required_nontarget:\n",
    "            break\n",
    "\n",
    "print(f\"✅ Đã sinh {nontarget_count} nontarget pairs\")\n",
    "\n",
    "# === 5. Spoof trials (file verification là spoof) ===\n",
    "# a) bonafide–spoof cùng speaker\n",
    "spoof_count = 0\n",
    "max_enroll_usage_spoof = 10\n",
    "enroll_usage_spoof = Counter()\n",
    "\n",
    "with open(output_file, \"a\") as f:\n",
    "    for spk in speakers:\n",
    "        for b in spk2bonafide[spk]:\n",
    "            if enroll_usage_spoof[b] >= max_enroll_usage_spoof:\n",
    "                continue\n",
    "            for s in spk2spoof.get(spk, []):\n",
    "                f.write(f\"{b} {s} spoof\\n\")\n",
    "                enroll_usage_spoof[b] += 1\n",
    "                spoof_count += 1\n",
    "\n",
    "    # b) bonafide–spoof khác speaker\n",
    "    for spk1 in speakers:\n",
    "        for spk2 in spk2spoof:\n",
    "            if spk1 == spk2:\n",
    "                continue\n",
    "            b_list = spk2bonafide[spk1]\n",
    "            s_list = spk2spoof[spk2]\n",
    "            if not s_list:\n",
    "                continue\n",
    "            random.shuffle(b_list)\n",
    "            for b in b_list:\n",
    "                if enroll_usage_spoof[b] >= max_enroll_usage_spoof:\n",
    "                    continue\n",
    "                s = random.choice(s_list)\n",
    "                f.write(f\"{b} {s} spoof\\n\")\n",
    "                enroll_usage_spoof[b] += 1\n",
    "                spoof_count += 1\n",
    "\n",
    "print(f\"✅ Đã sinh {spoof_count} spoof pairs\")\n",
    "print(f\"▶ Target: {target_count}\")\n",
    "print(f\"▶ Nontarget: {nontarget_count}\")\n",
    "print(f\"▶ Spoof: {spoof_count}\")\n",
    "print(f\"▶ Tổng cộng: {target_count + nontarget_count + spoof_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
